{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6081327,"sourceType":"datasetVersion","datasetId":3481545},{"sourceId":411715,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":336146,"modelId":356946},{"sourceId":411953,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":336336,"modelId":356946}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Set-up","metadata":{}},{"cell_type":"code","source":"!pip install evaluate --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T10:37:29.068654Z","iopub.execute_input":"2025-05-28T10:37:29.069083Z","iopub.status.idle":"2025-05-28T10:37:35.738315Z","shell.execute_reply.started":"2025-05-28T10:37:29.069020Z","shell.execute_reply":"2025-05-28T10:37:35.737223Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\n\nfrom datasets import Dataset\nfrom transformers import AutoModelForSequenceClassification, AutoModelForCausalLM, DataCollatorWithPadding, AutoTokenizer\nfrom transformers import TrainingArguments, Trainer\nfrom evaluate import load\n\nimport os\nfrom tqdm.auto import tqdm\nimport time\nimport random\n\nimport kagglehub\npath = kagglehub.dataset_download('haoshaoyang/sst5-data')\ndata_path = '/kaggle/input/sst5-data/'\nprint(list(os.walk(data_path)))\n\nimport wandb\nwandb.login(key=\"a505e496d38a3096fcef47944c848a5891788d98\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T10:37:35.739465Z","iopub.execute_input":"2025-05-28T10:37:35.739738Z","iopub.status.idle":"2025-05-28T10:38:16.267890Z","shell.execute_reply.started":"2025-05-28T10:37:35.739713Z","shell.execute_reply":"2025-05-28T10:38:16.266957Z"}},"outputs":[{"name":"stdout","text":"[('/kaggle/input/sst5-data/', ['sst'], []), ('/kaggle/input/sst5-data/sst', ['raw_data'], ['sst_dev.tsv', 'sst_test.tsv', 'README.md', 'sst_dev.txt', 'tree2tabular.py', 'sst_train.tsv', 'sst_test.txt', 'sst_train.txt']), ('/kaggle/input/sst5-data/sst/raw_data', [], ['test.txt', 'train.txt', 'dev.txt'])]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miq000012\u001b[0m (\u001b[33minfinitasfish\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# Dataset prep","metadata":{}},{"cell_type":"code","source":"train_file = os.path.join(data_path, 'sst/sst_train.txt')\ndev_file = os.path.join(data_path, 'sst/sst_dev.txt')\ntest_file = os.path.join(data_path, 'sst/sst_test.txt')\n\ntrain_df = pd.read_csv(train_file, delimiter='\\t', header=None)\ndev_df = pd.read_csv(dev_file, delimiter='\\t', header=None)\ntest_df = pd.read_csv(test_file, delimiter='\\t', header=None)\n\nprint(len(train_df), len(dev_df), len(test_df))\nprint(train_df[1].str.len().max(), dev_df[1].str.len().max(), test_df[1].str.len().max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T10:38:16.268786Z","iopub.execute_input":"2025-05-28T10:38:16.269791Z","iopub.status.idle":"2025-05-28T10:38:16.389606Z","shell.execute_reply.started":"2025-05-28T10:38:16.269755Z","shell.execute_reply":"2025-05-28T10:38:16.388652Z"}},"outputs":[{"name":"stdout","text":"8544 1101 2210\n267 254 256\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_df)\ntrain_dataset = train_dataset.rename_columns({'0': 'labels', '1': 'text'})\n\nval_dataset = Dataset.from_pandas(dev_df)\nval_dataset = val_dataset.rename_columns({'0': 'labels', '1': 'text'})\n\ntest_dataset = Dataset.from_pandas(test_df)\ntest_dataset = test_dataset.rename_columns({'0': 'labels', '1': 'text'})\n\ntext_labels = ['__label__1', '__label__2', '__label__3', '__label__4', '__label__5']\nlabel_dict = {k:i for i, k in enumerate(text_labels)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T10:38:16.392201Z","iopub.execute_input":"2025-05-28T10:38:16.392643Z","iopub.status.idle":"2025-05-28T10:38:16.442221Z","shell.execute_reply.started":"2025-05-28T10:38:16.392611Z","shell.execute_reply":"2025-05-28T10:38:16.441155Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T10:38:16.443635Z","iopub.execute_input":"2025-05-28T10:38:16.443988Z","iopub.status.idle":"2025-05-28T10:38:18.479374Z","shell.execute_reply.started":"2025-05-28T10:38:16.443952Z","shell.execute_reply":"2025-05-28T10:38:18.478542Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98fa5520d87340d2b730f10953ae9737"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8c38d8523304f68b80e4047bdd94364"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d2a86f85b54333acc7d500f75d584b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03dd86d9efd246cab91caeb7d7552005"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def preprocess_function(examples):\n   return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=256)\n\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_val = val_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)\n\ntokenized_train = tokenized_train.map(lambda e: {'labels': label_dict[e['labels']]})\ntokenized_val = tokenized_val.map(lambda e: {'labels': label_dict[e['labels']]})\ntokenized_test = tokenized_test.map(lambda e: {'labels': label_dict[e['labels']]})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T10:38:18.480179Z","iopub.execute_input":"2025-05-28T10:38:18.480454Z","iopub.status.idle":"2025-05-28T10:38:21.583216Z","shell.execute_reply.started":"2025-05-28T10:38:18.480428Z","shell.execute_reply":"2025-05-28T10:38:21.582001Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8544 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b34a2f2d4a864ec7b294e3b037a245c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1101 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b43ded2bc9bc4c05aa4cb7bff81c9fd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2210 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30eea9b5bfbe452397daf08ce7402e2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8544 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cb00435a66d404c991958069c3d7ed3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1101 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f08e5328df294e5981a48fcf6cb59645"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2210 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d87ca5ad18a46a2812dbddac281d0f0"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T10:38:21.584594Z","iopub.execute_input":"2025-05-28T10:38:21.585012Z","iopub.status.idle":"2025-05-28T10:38:21.589462Z","shell.execute_reply.started":"2025-05-28T10:38:21.584973Z","shell.execute_reply":"2025-05-28T10:38:21.588417Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Pretrained ransformers baseline, clf head only ('eval_f1': macro 0.4636)","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment')\n\n# only 3 labels\nmodel.classifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:04:31.548091Z","iopub.execute_input":"2025-05-25T13:04:31.548424Z","iopub.status.idle":"2025-05-25T13:04:34.144483Z","shell.execute_reply.started":"2025-05-25T13:04:31.548395Z","shell.execute_reply":"2025-05-25T13:04:34.143466Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"258ed5410a3b45f789163b6ddc0d0e5e"}},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"RobertaClassificationHead(\n  (dense): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (out_proj): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"\nf1_metric = load(\"f1\")\naccuracy_metric = load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    \n    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n    \n    return {\n        \"f1\": f1,\n        \"accuracy\": accuracy,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:15:26.307312Z","iopub.execute_input":"2025-05-25T13:15:26.307688Z","iopub.status.idle":"2025-05-25T13:15:27.544873Z","shell.execute_reply.started":"2025-05-25T13:15:26.307660Z","shell.execute_reply":"2025-05-25T13:15:27.544234Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c88fba9fdac4c43bd3478b7e6b72743"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35adb698900947c6aa0e3de11c886454"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"class RobertaSentiment(nn.Module):\n    def __init__(self, model_name, num_labels):\n        super().__init__()\n        \n        full_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n        self.roberta = full_model.roberta\n        self.classifier = nn.Sequential(nn.Linear(768, 768, bias=True),\n                                        nn.Dropout(p=0.1, inplace=False),\n                                        nn.Linear(768, num_labels, bias=True))    \n        self.loss_fn = nn.CrossEntropyLoss()\n        del full_model\n        \n        # frozen backbone\n        for param in self.roberta.parameters():\n            param.requires_grad = False\n    \n\n    def forward(self, input_ids, attention_mask, labels=None, **kwargs):\n        out = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        pool = out.last_hidden_state[:, 0, :]\n        logits = self.classifier(pool)\n        \n        if labels is not None:\n            loss = self.loss_fn(logits, labels)\n            return {\"loss\": loss, \"logits\": logits}\n        return {\"logits\": logits}\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:15:40.872178Z","iopub.execute_input":"2025-05-25T13:15:40.872494Z","iopub.status.idle":"2025-05-25T13:15:40.878591Z","shell.execute_reply.started":"2025-05-25T13:15:40.872472Z","shell.execute_reply":"2025-05-25T13:15:40.877559Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"MODEL = RobertaSentiment(model_name='cardiffnlp/twitter-roberta-base-sentiment', num_labels=5)\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nLR = 2e-5\nBATCH_SIZE = 64\nEPOCHS = 20\n\nMODEL.to(DEVICE);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:16:36.269515Z","iopub.execute_input":"2025-05-25T13:16:36.269923Z","iopub.status.idle":"2025-05-25T13:16:36.786095Z","shell.execute_reply.started":"2025-05-25T13:16:36.269891Z","shell.execute_reply":"2025-05-25T13:16:36.784538Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='/kaggle/working',\n    remove_unused_columns=True,\n    learning_rate=LR,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    num_train_epochs=EPOCHS,\n    weight_decay=0.01,\n    save_strategy='epoch',\n    save_total_limit=3,\n    eval_strategy='epoch',\n    logging_steps=50,\n    report_to='wandb',\n    run_name='stt5_twitterbert_finetune_2005',\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n)\n\ntrainer = Trainer(\n   model=MODEL,\n   args=training_args,\n   train_dataset=tokenized_train,\n   eval_dataset=tokenized_val,\n   processing_class=tokenizer,\n   data_collator=data_collator,\n   compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:16:37.869680Z","iopub.execute_input":"2025-05-25T13:16:37.870059Z","iopub.status.idle":"2025-05-25T13:16:37.913281Z","shell.execute_reply.started":"2025-05-25T13:16:37.870026Z","shell.execute_reply":"2025-05-25T13:16:37.912623Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:16:41.210357Z","iopub.execute_input":"2025-05-25T13:16:41.210707Z","iopub.status.idle":"2025-05-25T13:42:21.168060Z","shell.execute_reply.started":"2025-05-25T13:16:41.210684Z","shell.execute_reply":"2025-05-25T13:42:21.167310Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250525_131641-q3umpejf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/infinitasfish/huggingface/runs/q3umpejf' target=\"_blank\">stt5_twitterbert_finetune_2005</a></strong> to <a href='https://wandb.ai/infinitasfish/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/infinitasfish/huggingface' target=\"_blank\">https://wandb.ai/infinitasfish/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/infinitasfish/huggingface/runs/q3umpejf' target=\"_blank\">https://wandb.ai/infinitasfish/huggingface/runs/q3umpejf</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2680' max='2680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2680/2680 25:31, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.242900</td>\n      <td>1.203771</td>\n      <td>0.407464</td>\n      <td>0.460490</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.198800</td>\n      <td>1.185892</td>\n      <td>0.445293</td>\n      <td>0.462307</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.183600</td>\n      <td>1.181465</td>\n      <td>0.421239</td>\n      <td>0.459582</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.177400</td>\n      <td>1.174404</td>\n      <td>0.448004</td>\n      <td>0.474114</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.187500</td>\n      <td>1.166214</td>\n      <td>0.449519</td>\n      <td>0.475931</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.169000</td>\n      <td>1.161175</td>\n      <td>0.436516</td>\n      <td>0.469573</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.175800</td>\n      <td>1.161925</td>\n      <td>0.451805</td>\n      <td>0.475931</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.171700</td>\n      <td>1.151691</td>\n      <td>0.457570</td>\n      <td>0.481381</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.170700</td>\n      <td>1.151176</td>\n      <td>0.450070</td>\n      <td>0.478656</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.161600</td>\n      <td>1.155669</td>\n      <td>0.452665</td>\n      <td>0.481381</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.167800</td>\n      <td>1.145377</td>\n      <td>0.452595</td>\n      <td>0.475931</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.157600</td>\n      <td>1.145871</td>\n      <td>0.448849</td>\n      <td>0.478656</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>1.161800</td>\n      <td>1.146929</td>\n      <td>0.463644</td>\n      <td>0.485922</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.147700</td>\n      <td>1.140790</td>\n      <td>0.450466</td>\n      <td>0.476839</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.145000</td>\n      <td>1.143716</td>\n      <td>0.455085</td>\n      <td>0.481381</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.160100</td>\n      <td>1.140904</td>\n      <td>0.453183</td>\n      <td>0.480472</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.146100</td>\n      <td>1.138762</td>\n      <td>0.454581</td>\n      <td>0.482289</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.136500</td>\n      <td>1.139213</td>\n      <td>0.456628</td>\n      <td>0.484105</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.149200</td>\n      <td>1.140059</td>\n      <td>0.453613</td>\n      <td>0.481381</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.129000</td>\n      <td>1.139758</td>\n      <td>0.456543</td>\n      <td>0.483197</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2680, training_loss=1.1695085013090674, metrics={'train_runtime': 1539.4694, 'train_samples_per_second': 110.999, 'train_steps_per_second': 1.741, 'total_flos': 0.0, 'train_loss': 1.1695085013090674, 'epoch': 20.0})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T13:42:21.169087Z","iopub.execute_input":"2025-05-25T13:42:21.169375Z","iopub.status.idle":"2025-05-25T13:42:29.443138Z","shell.execute_reply.started":"2025-05-25T13:42:21.169352Z","shell.execute_reply":"2025-05-25T13:42:29.442433Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [18/18 00:07]\n    </div>\n    "},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.1469286680221558,\n 'eval_f1': 0.46364350399575144,\n 'eval_accuracy': 0.485921889191644,\n 'eval_runtime': 8.2652,\n 'eval_samples_per_second': 133.209,\n 'eval_steps_per_second': 2.178,\n 'epoch': 20.0}"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"# Same baseline, encoder+embeds unfreezing","metadata":{}},{"cell_type":"code","source":"class RobertaSentimentUnfreeze(nn.Module):\n    def __init__(self, model_name, num_labels, unfreeze_strat, unfreeze_epoch):\n        super().__init__()\n        \n        full_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n        self.roberta = full_model.roberta\n        self.classifier = nn.Sequential(nn.Linear(768, 768, bias=True),\n                                        nn.Dropout(p=0.1, inplace=False),\n                                        nn.Linear(768, num_labels, bias=True))    \n        self.loss_fn = nn.CrossEntropyLoss()\n        del full_model\n        \n        self.unfreeze_strat = unfreeze_strat\n        self.encoder_layers = len(self.roberta.encoder.layer)\n        self.is_unfreezed = False\n        self.unfreeze_epoch = unfreeze_epoch\n        self._freeze_all()\n\n\n    def _freeze_all(self):\n        for param in self.roberta.parameters():\n            param.requires_grad = False\n\n    def _unfreeze_all_after_n(self, epoch):\n        if epoch > self.unfreeze_epoch:\n            print('unfreezing all')\n            for param in self.roberta.parameters():\n                param.requires_grad = True\n            self.is_unfreezed = True        \n\n    def _unfreeze_layerwise(self, epoch):\n        if epoch <= self.unfreeze_epoch:\n            return\n\n        # unfreeze 1 layer each '// n' epoch\n        layers_to_unfreeze = min((epoch - self.unfreeze_epoch) // 8, self.encoder_layers)\n        for i in range(self.encoder_layers - layers_to_unfreeze, self.encoder_layers):\n            for param in self.roberta.encoder.layer[i].parameters():\n                param.requires_grad = True\n                \n        print(f'unfreezing {layers_to_unfreeze} top layers')\n\n        if layers_to_unfreeze >= self.encoder_layers:\n            self.is_unfreezed = True\n\n    def update_unfreeze_status(self, epoch):\n        if self.is_unfreezed:\n            return\n        elif self.unfreeze_strat == 'after_n':\n            self._unfreeze_all_after_n(epoch)\n        elif self.unfreeze_strat == 'layerwise':\n            self._unfreeze_layerwise(epoch)\n\n    def forward(self, input_ids, attention_mask, labels=None, **kwargs):\n        out = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n        pool = out.last_hidden_state[:, 0, :]\n        logits = self.classifier(pool)\n        \n        if labels is not None:\n            loss = self.loss_fn(logits, labels)\n            return {\"loss\": loss, \"logits\": logits}\n        return {\"logits\": logits}\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T10:38:21.590536Z","iopub.execute_input":"2025-05-28T10:38:21.590844Z","iopub.status.idle":"2025-05-28T10:38:21.604847Z","shell.execute_reply.started":"2025-05-28T10:38:21.590820Z","shell.execute_reply":"2025-05-28T10:38:21.603844Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\nUNFREEZE_EPOCH = 3\n# MODEL = RobertaSentimentUnfreeze(model_name='cardiffnlp/twitter-roberta-base-sentiment', \n#                                  num_labels=5, unfreeze_strat='after_n', unfreeze_epoch=UNFREEZE_EPOCH)\n\nMODEL = RobertaSentimentUnfreeze(model_name='cardiffnlp/twitter-roberta-base-sentiment', \n                                 num_labels=5, unfreeze_strat='layerwise', unfreeze_epoch=UNFREEZE_EPOCH)\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nCLF_LR = 8e-5\nBACKBONE_LR = 8e-5\nWD = 0.01\nBATCH_SIZE = 26\nEPOCHS = 40\n\nTRAIN_LOSSI = []\nVAL_LOSSI = []\n\ntorch.cuda.empty_cache()\nMODEL.to(DEVICE);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T10:38:21.605797Z","iopub.execute_input":"2025-05-28T10:38:21.606337Z","iopub.status.idle":"2025-05-28T10:38:24.348088Z","shell.execute_reply.started":"2025-05-28T10:38:21.606306Z","shell.execute_reply":"2025-05-28T10:38:24.346481Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8923fbedd7c41609b764ecf99010065"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"classifier_params = sum(p.numel() for p in MODEL.classifier.parameters())\nroberta_params = sum(p.numel() for p in MODEL.roberta.parameters())\ntotal_params = classifier_params + roberta_params\n\nprint(f'Model contains {total_params:,} parameters')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T11:20:02.600683Z","iopub.execute_input":"2025-05-28T11:20:02.601259Z","iopub.status.idle":"2025-05-28T11:20:02.610639Z","shell.execute_reply.started":"2025-05-28T11:20:02.601209Z","shell.execute_reply":"2025-05-28T11:20:02.609500Z"}},"outputs":[{"name":"stdout","text":"Model contains 124,649,477 parameters\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def collate_fn(batch):\n    return {\n        'input_ids': torch.stack([torch.tensor(x['input_ids']) for x in batch]),\n        'attention_mask': torch.stack([torch.tensor(x['attention_mask']) for x in batch]),\n        'labels': torch.tensor([x['labels'] for x in batch])\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T16:48:55.655995Z","iopub.execute_input":"2025-05-26T16:48:55.656286Z","iopub.status.idle":"2025-05-26T16:48:55.670106Z","shell.execute_reply.started":"2025-05-26T16:48:55.656259Z","shell.execute_reply":"2025-05-26T16:48:55.669280Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_loader = DataLoader(tokenized_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(tokenized_val, batch_size=BATCH_SIZE, collate_fn=collate_fn)\ntest_loader = DataLoader(tokenized_test, batch_size=BATCH_SIZE, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T06:27:08.047662Z","iopub.execute_input":"2025-05-26T06:27:08.047902Z","iopub.status.idle":"2025-05-26T06:27:08.053022Z","shell.execute_reply.started":"2025-05-26T06:27:08.047881Z","shell.execute_reply":"2025-05-26T06:27:08.052217Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def train_loop(model, train_loader, val_loader, epochs, clf_lr, back_lr, wd, tlossi, vlossi, tf1s, vf1s, save_fname):\n    \n    optimizer = AdamW([\n        {'params': model.classifier.parameters(), 'lr': clf_lr},\n        {'params': [p for p in model.roberta.parameters() if p.requires_grad], 'lr': back_lr}\n    ], weight_decay=wd)\n\n    load_f1 = load(\"f1\")\n    load_accuracy = load(\"accuracy\")\n    best_val_metrics_sum = -1\n\n    for epoch in tqdm(range(epochs)):\n\n        # basic lr scheduler\n        if epoch > 5:\n            clf_lr *= 0.9\n            back_lr *= 0.9\n        \n        model.update_unfreeze_status(epoch)\n\n        new_unfreezed_params = [p for p in model.roberta.parameters() if p.requires_grad]\n        \n        param_groups = [\n            {'params': model.classifier.parameters(), 'lr': clf_lr},\n            {'params': new_unfreezed_params, 'lr': back_lr}\n        ]\n        optimizer = AdamW(param_groups, weight_decay=wd)\n\n        all_preds_train = []\n        all_labels_train = []\n        model.train()\n        train_loss = 0\n        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n            inputs = batch['input_ids'].to(DEVICE)\n            masks = batch['attention_mask'].to(DEVICE)\n            labels = batch['labels'].to(DEVICE)\n            \n            optimizer.zero_grad()\n            outputs = model(input_ids=inputs, attention_mask=masks, labels=labels)\n            logits = outputs['logits']\n            loss = outputs['loss']\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n            train_loss += loss.item()\n\n            preds = logits.argmax(dim=-1).detach().cpu().numpy()\n            all_preds_train.extend(preds)\n            all_labels_train.extend(labels)\n\n        epoch_train_loss = train_loss/len(train_loader)\n        epoch_train_f1 = load_f1.compute(predictions=all_preds_train, references=all_labels_train, average='macro')[\"f1\"]\n        \n        tlossi.append(epoch_train_loss)\n        tf1s.append(epoch_train_f1)\n\n        all_preds_val = []\n        all_labels_val = []\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                inputs = batch['input_ids'].to(DEVICE)\n                masks = batch['attention_mask'].to(DEVICE)\n                labels = batch['labels'].to(DEVICE)\n                \n                outputs = model(input_ids=inputs, attention_mask=masks, labels=labels)\n                logits = outputs['logits']\n                loss = outputs['loss']\n                val_loss += loss.item()\n                \n                preds = logits.argmax(dim=-1).detach().cpu().numpy()\n                all_preds_val.extend(preds)\n                all_labels_val.extend(labels)\n                \n        epoch_val_loss = val_loss/len(val_loader)\n        epoch_val_f1 = load_f1.compute(predictions=all_preds_val, references=all_labels_val, average='macro')[\"f1\"]\n        epoch_val_acc = load_accuracy.compute(predictions=all_preds_val, references=all_labels_val)[\"accuracy\"]\n        vlossi.append(epoch_val_loss)\n        vf1s.append(epoch_val_f1)\n\n        val_metrics_sum = epoch_val_f1 + epoch_val_acc\n        # save best model\n        if val_metrics_sum > best_val_metrics_sum:\n            best_val_metrics_sum = val_metrics_sum\n            torch.save(model.state_dict(), f'{save_fname}.pth')\n            \n            \n        print(f'Epoch {epoch+1} | Train Loss: {epoch_train_loss:.4f} | Train F1: {epoch_train_f1:.4f} | Val Loss: {epoch_val_loss:.4f} | Val F1: {epoch_val_f1:.4f} | Val Acc: {epoch_val_acc:.4f}')\n        torch.cuda.empty_cache()\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T16:40:58.410957Z","iopub.execute_input":"2025-05-26T16:40:58.411263Z","iopub.status.idle":"2025-05-26T16:40:58.422316Z","shell.execute_reply.started":"2025-05-26T16:40:58.411238Z","shell.execute_reply":"2025-05-26T16:40:58.421524Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_lossi = []\ntrain_f1s = []\nval_lossi = []\nval_f1s = []\n\ns = time.time()\ntrain_loop(MODEL, train_loader, val_loader, EPOCHS, CLF_LR, BACKBONE_LR, WD, train_lossi, val_lossi, train_f1s, val_f1s, 'layerwise_model_weights')\ne = time.time()\nprint(f'Training completed in {(e-s)/60:.4f} mins')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:02:55.381224Z","iopub.execute_input":"2025-05-25T20:02:55.381506Z","iopub.status.idle":"2025-05-25T21:07:04.884379Z","shell.execute_reply.started":"2025-05-25T20:02:55.381484Z","shell.execute_reply":"2025-05-25T21:07:04.883474Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36a3cf5a6ecc480494f55fcff3b11c0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb5388c651604da0a3b984293c39620d"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.2154 | Train F1: 0.4154 | Val Loss: 1.1609 | Val F1: 0.4478 | Val Acc: 0.4723\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00d560d0efab4e4aa589e0fc383dcc9c"}},"metadata":{}},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.1700 | Train F1: 0.4414 | Val Loss: 1.1311 | Val F1: 0.4609 | Val Acc: 0.4805\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e8ae814a2624dffaa56faff326329b8"}},"metadata":{}},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.1543 | Train F1: 0.4533 | Val Loss: 1.1424 | Val F1: 0.4225 | Val Acc: 0.4759\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beed81381386483d84671f0c504af81e"}},"metadata":{}},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.1316 | Train F1: 0.4650 | Val Loss: 1.1601 | Val F1: 0.4560 | Val Acc: 0.4886\nunfreezing 0 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a55105ef48c46c38801e0511d478c0f"}},"metadata":{}},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.1382 | Train F1: 0.4591 | Val Loss: 1.1373 | Val F1: 0.4813 | Val Acc: 0.4868\nunfreezing 0 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9658cfc37544af8bafe704aa40d0676"}},"metadata":{}},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.1217 | Train F1: 0.4621 | Val Loss: 1.1349 | Val F1: 0.4416 | Val Acc: 0.4914\nunfreezing 0 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f90a131be6e242d68cf1fae1302264a5"}},"metadata":{}},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.1234 | Train F1: 0.4726 | Val Loss: 1.1405 | Val F1: 0.4719 | Val Acc: 0.4932\nunfreezing 0 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fed2c403c474055a4d8d749b3805629"}},"metadata":{}},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.1168 | Train F1: 0.4753 | Val Loss: 1.1168 | Val F1: 0.4571 | Val Acc: 0.4896\nunfreezing 0 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be1ec40dabba45f692313a1839c37773"}},"metadata":{}},{"name":"stdout","text":"Epoch 9 | Train Loss: 1.1174 | Train F1: 0.4743 | Val Loss: 1.1266 | Val F1: 0.4771 | Val Acc: 0.5014\nunfreezing 0 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea8ff06e7ff644b6ae994208af9c70c0"}},"metadata":{}},{"name":"stdout","text":"Epoch 10 | Train Loss: 1.1136 | Train F1: 0.4741 | Val Loss: 1.1169 | Val F1: 0.4765 | Val Acc: 0.4995\nunfreezing 0 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"807a2718737e4d6497c5e3fe7f4a873e"}},"metadata":{}},{"name":"stdout","text":"Epoch 11 | Train Loss: 1.1087 | Train F1: 0.4756 | Val Loss: 1.1185 | Val F1: 0.4888 | Val Acc: 0.5032\nunfreezing 1 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80662441fc484684a5695dce6a975e5e"}},"metadata":{}},{"name":"stdout","text":"Epoch 12 | Train Loss: 1.1287 | Train F1: 0.4708 | Val Loss: 1.1702 | Val F1: 0.4520 | Val Acc: 0.4832\nunfreezing 1 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3395f7752b924b798ac97c18aec79dbe"}},"metadata":{}},{"name":"stdout","text":"Epoch 13 | Train Loss: 1.1099 | Train F1: 0.4824 | Val Loss: 1.1264 | Val F1: 0.4496 | Val Acc: 0.4995\nunfreezing 1 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca9c6992a892480a9b769c3be2a51d48"}},"metadata":{}},{"name":"stdout","text":"Epoch 14 | Train Loss: 1.0974 | Train F1: 0.4802 | Val Loss: 1.1281 | Val F1: 0.4736 | Val Acc: 0.5123\nunfreezing 1 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 15:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9349d63b9f1549faaead9ff8f7821eb4"}},"metadata":{}},{"name":"stdout","text":"Epoch 15 | Train Loss: 1.0722 | Train F1: 0.4979 | Val Loss: 1.1056 | Val F1: 0.4407 | Val Acc: 0.4995\nunfreezing 1 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 16:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"537ee2def56c4b8ab0bb1c5b26084c9b"}},"metadata":{}},{"name":"stdout","text":"Epoch 16 | Train Loss: 1.0640 | Train F1: 0.5049 | Val Loss: 1.1065 | Val F1: 0.4787 | Val Acc: 0.5059\nunfreezing 1 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 17:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e046b243966435b9f8dc44f738d3deb"}},"metadata":{}},{"name":"stdout","text":"Epoch 17 | Train Loss: 1.0517 | Train F1: 0.5091 | Val Loss: 1.1220 | Val F1: 0.4917 | Val Acc: 0.4932\nunfreezing 1 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 18:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"839ea3fbe3c549d0be70aced742fb05d"}},"metadata":{}},{"name":"stdout","text":"Epoch 18 | Train Loss: 1.0418 | Train F1: 0.5146 | Val Loss: 1.1358 | Val F1: 0.4837 | Val Acc: 0.4950\nunfreezing 1 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 19:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe252256adcd4e7aa750097d490cc333"}},"metadata":{}},{"name":"stdout","text":"Epoch 19 | Train Loss: 1.0302 | Train F1: 0.5218 | Val Loss: 1.1097 | Val F1: 0.4986 | Val Acc: 0.5068\nunfreezing 2 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 20:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52813c75018f4bb7b51b207885f216e5"}},"metadata":{}},{"name":"stdout","text":"Epoch 20 | Train Loss: 1.0331 | Train F1: 0.5219 | Val Loss: 1.1555 | Val F1: 0.4652 | Val Acc: 0.4750\nunfreezing 2 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 21:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8e4c061d4074fb9b4e6ad2a76d6ee50"}},"metadata":{}},{"name":"stdout","text":"Epoch 21 | Train Loss: 1.0126 | Train F1: 0.5306 | Val Loss: 1.1174 | Val F1: 0.4944 | Val Acc: 0.5041\nunfreezing 2 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 22:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c45a507b233409bbbece0587470c914"}},"metadata":{}},{"name":"stdout","text":"Epoch 22 | Train Loss: 0.9916 | Train F1: 0.5430 | Val Loss: 1.1493 | Val F1: 0.4967 | Val Acc: 0.5104\nunfreezing 2 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 23:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0a720ffcab54ea298c6af52c0b406ad"}},"metadata":{}},{"name":"stdout","text":"Epoch 23 | Train Loss: 0.9715 | Train F1: 0.5646 | Val Loss: 1.1320 | Val F1: 0.4980 | Val Acc: 0.5114\nunfreezing 2 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 24:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c762fba740d49ecb7bfcf35f7b91881"}},"metadata":{}},{"name":"stdout","text":"Epoch 24 | Train Loss: 0.9583 | Train F1: 0.5668 | Val Loss: 1.1638 | Val F1: 0.4878 | Val Acc: 0.4923\nunfreezing 2 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 25:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24c3159072444a20bd920abca64bebaa"}},"metadata":{}},{"name":"stdout","text":"Epoch 25 | Train Loss: 0.9370 | Train F1: 0.5752 | Val Loss: 1.1474 | Val F1: 0.4930 | Val Acc: 0.5104\nunfreezing 2 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 26:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b950fde6ad164beaabffaf3a28344619"}},"metadata":{}},{"name":"stdout","text":"Epoch 26 | Train Loss: 0.9214 | Train F1: 0.5787 | Val Loss: 1.1891 | Val F1: 0.4831 | Val Acc: 0.4886\nunfreezing 2 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 27:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"736e96fb73804c3cbdd0f110ce4a98c5"}},"metadata":{}},{"name":"stdout","text":"Epoch 27 | Train Loss: 0.9107 | Train F1: 0.5876 | Val Loss: 1.2334 | Val F1: 0.4738 | Val Acc: 0.4914\nunfreezing 3 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 28:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f3a5259e74d4ca2adfc70395a4ddb81"}},"metadata":{}},{"name":"stdout","text":"Epoch 28 | Train Loss: 0.9049 | Train F1: 0.5872 | Val Loss: 1.2246 | Val F1: 0.4734 | Val Acc: 0.4823\nunfreezing 3 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 29:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e09e3e1b8eb404ca9147132f673f114"}},"metadata":{}},{"name":"stdout","text":"Epoch 29 | Train Loss: 0.8892 | Train F1: 0.5950 | Val Loss: 1.1933 | Val F1: 0.4861 | Val Acc: 0.4932\nunfreezing 3 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 30:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89e062f231544409b81e457ee2e44e6e"}},"metadata":{}},{"name":"stdout","text":"Epoch 30 | Train Loss: 0.8626 | Train F1: 0.6213 | Val Loss: 1.2012 | Val F1: 0.4917 | Val Acc: 0.5077\nunfreezing 3 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 31:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c90a162eb75e4e3abeb3008251ebab16"}},"metadata":{}},{"name":"stdout","text":"Epoch 31 | Train Loss: 0.8503 | Train F1: 0.6217 | Val Loss: 1.2395 | Val F1: 0.4904 | Val Acc: 0.5023\nunfreezing 3 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 32:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29d85f8255dd42fe9fdd752925a871ec"}},"metadata":{}},{"name":"stdout","text":"Epoch 32 | Train Loss: 0.8366 | Train F1: 0.6274 | Val Loss: 1.2215 | Val F1: 0.4850 | Val Acc: 0.5059\nunfreezing 3 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 33:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4e3f467396e4dd3a63246a2167b2cbe"}},"metadata":{}},{"name":"stdout","text":"Epoch 33 | Train Loss: 0.8326 | Train F1: 0.6322 | Val Loss: 1.2187 | Val F1: 0.4911 | Val Acc: 0.5023\nunfreezing 3 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 34:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9c9404c2f2c46d186680470d02e130f"}},"metadata":{}},{"name":"stdout","text":"Epoch 34 | Train Loss: 0.8149 | Train F1: 0.6423 | Val Loss: 1.2645 | Val F1: 0.4870 | Val Acc: 0.4941\nunfreezing 3 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 35:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc102899b1ce441c90ee210150c392ba"}},"metadata":{}},{"name":"stdout","text":"Epoch 35 | Train Loss: 0.8015 | Train F1: 0.6537 | Val Loss: 1.2553 | Val F1: 0.4919 | Val Acc: 0.4986\nunfreezing 4 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 36:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27ff64fe60494ff88928a81b2da9da82"}},"metadata":{}},{"name":"stdout","text":"Epoch 36 | Train Loss: 0.7908 | Train F1: 0.6531 | Val Loss: 1.2347 | Val F1: 0.4829 | Val Acc: 0.4977\nunfreezing 4 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 37:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fdec2ba75ec44f39485a30b153c1c6d"}},"metadata":{}},{"name":"stdout","text":"Epoch 37 | Train Loss: 0.7805 | Train F1: 0.6566 | Val Loss: 1.2598 | Val F1: 0.4897 | Val Acc: 0.4977\nunfreezing 4 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 38:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"668768d89eae44808ec7208614d09284"}},"metadata":{}},{"name":"stdout","text":"Epoch 38 | Train Loss: 0.7611 | Train F1: 0.6669 | Val Loss: 1.2618 | Val F1: 0.5020 | Val Acc: 0.5050\nunfreezing 4 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 39:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e72e8abb11bc42c69b80f4228d7240f6"}},"metadata":{}},{"name":"stdout","text":"Epoch 39 | Train Loss: 0.7561 | Train F1: 0.6705 | Val Loss: 1.2639 | Val F1: 0.4911 | Val Acc: 0.5059\nunfreezing 4 top layers\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 40:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88cefd89e4ea452383681b8d90213722"}},"metadata":{}},{"name":"stdout","text":"Epoch 40 | Train Loss: 0.7494 | Train F1: 0.6739 | Val Loss: 1.2669 | Val F1: 0.5075 | Val Acc: 0.5123\nTraining completed in 64.1583 mins\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"def evaluate_model(model, val_loader):\n    accuracy_metric = load(\"accuracy\")\n    f1_metric = load(\"f1\")\n    \n    all_preds_val = []\n    all_labels_val = []\n    model.eval()\n    with torch.no_grad():\n        for batch in val_loader:\n            inputs = batch['input_ids'].to(DEVICE)\n            masks = batch['attention_mask'].to(DEVICE)\n            labels = batch['labels'].to(DEVICE)\n                \n            outputs = model(input_ids=inputs, attention_mask=masks, labels=labels)\n            logits = outputs['logits']\n                \n            preds = logits.argmax(dim=-1).detach().cpu().numpy()\n            all_preds_val.extend(preds)\n            all_labels_val.extend(labels)\n                \n    val_f1 = f1_metric.compute(predictions=all_preds_val, references=all_labels_val, average='macro')[\"f1\"]\n    val_acc = accuracy_metric.compute(predictions=all_preds_val, references=all_labels_val)[\"accuracy\"]\n    return {\n        \"f1\": val_f1,\n        \"accuracy\": val_acc,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T16:48:55.671807Z","iopub.execute_input":"2025-05-26T16:48:55.672065Z","iopub.status.idle":"2025-05-26T16:48:55.685902Z","shell.execute_reply.started":"2025-05-26T16:48:55.672044Z","shell.execute_reply":"2025-05-26T16:48:55.685087Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"MODEL.load_state_dict(torch.load('/kaggle/input/sst5_tuned/pytorch/sst5_full_tuned_0525/1/after_n_model_weights_0525.pth', map_location=DEVICE, weights_only=True))\nprint(evaluate_model(MODEL, test_loader))\nMODEL.load_state_dict(torch.load('/kaggle/working/layerwise_model_weights.pth', map_location=DEVICE, weights_only=True))\nprint(evaluate_model(MODEL, test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T21:26:40.096930Z","iopub.execute_input":"2025-05-25T21:26:40.097254Z","iopub.status.idle":"2025-05-25T21:27:15.806147Z","shell.execute_reply.started":"2025-05-25T21:26:40.097230Z","shell.execute_reply":"2025-05-25T21:27:15.805361Z"}},"outputs":[{"name":"stdout","text":"{'f1': 0.561599363852188, 'accuracy': 0.5669683257918552}\n{'f1': 0.5283791696600086, 'accuracy': 0.5425339366515837}\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"# Trained full model + prompted dataset 'f1 macro': 0.5556695031280695, 'accuracy': 0.574660633484162","metadata":{}},{"cell_type":"code","source":"# llm_model_name = 'HuggingFaceH4/zephyr-7b-alpha'\n# llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n# llm_model = AutoModelForCausalLM.from_pretrained(llm_model_name, torch_dtype=torch.float16, device_map=\"auto\")\n\ndef generate_prompts(initial_prompt, model, tokenizer, num_variants=5):\n    prompts = []\n    for _ in range(num_variants):\n        input_text = f\"<|system|>Rephrase the following prompt for sentiment analysis, keeping the core meaning but varying the style:</s>\\n<|user|>Original: {initial_prompt}\\nNew:</s>\\n<|assistant|>\"\n        inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n        outputs = model.generate(**inputs, max_new_tokens=150, do_sample=True)\n        new_prompt = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"New:\")[-1].strip()\n        prompts.append(new_prompt)\n    return prompts\n\ninitial_prompt = '''Movie review sentiment classification task: \nFrom the following five options - very negative, negative, neutral, positive, or very positive (0-4) - which best describes this review? '''\n\n# generated_prompts = generate_prompts(initial_prompt, llm_model, llm_tokenizer)\n\n# <|assistant|>Sentiment analysis task: Identify the sentiment of a given movie review based on whether it is very negative, negative, neutral, positive, or very positive. Which option aligns best with the review's overall tone?\n# selected_llm_prompt = generated_prompts[0]\n# print(selected_llm_prompt)\n\n# selected_llm_prompt = \"<|assistant|>Sentiment analysis task: Identify the sentiment of a given movie review based on whether it is very negative, negative, neutral, positive, or very positive. Which option aligns best with the review's overall tone?\"\nselected_llm_prompt = initial_prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T16:48:55.687038Z","iopub.execute_input":"2025-05-26T16:48:55.687321Z","iopub.status.idle":"2025-05-26T16:48:55.699619Z","shell.execute_reply.started":"2025-05-26T16:48:55.687297Z","shell.execute_reply":"2025-05-26T16:48:55.698903Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"text_wprompt = [f'{selected_llm_prompt}\\n\\nReview: {text}\\n\\nSentiment:' for text in train_dataset['text']]\ntrain_dataset = train_dataset.add_column(\"text_wprompt\", text_wprompt)\n\ntext_wprompt_val = [f'{selected_llm_prompt}\\n\\nReview: {text}\\n\\nSentiment:' for text in val_dataset['text']]\nval_dataset = val_dataset.add_column(\"text_wprompt\", text_wprompt_val)\n\ntext_wprompt_test = [f'{selected_llm_prompt}\\n\\nReview: {text}\\n\\nSentiment:' for text in test_dataset['text']]\ntest_dataset = test_dataset.add_column(\"text_wprompt\", text_wprompt_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T16:48:55.700368Z","iopub.execute_input":"2025-05-26T16:48:55.700635Z","iopub.status.idle":"2025-05-26T16:48:55.778675Z","shell.execute_reply.started":"2025-05-26T16:48:55.700603Z","shell.execute_reply":"2025-05-26T16:48:55.778047Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def preprocess_function_wprompt(examples):\n    return tokenizer(examples['text_wprompt'], truncation=True, padding='max_length', max_length=512)\n\ntokenized_wprompt_train = train_dataset.map(preprocess_function_wprompt, batched=True)\ntokenized_wprompt_val = val_dataset.map(preprocess_function_wprompt, batched=True)\ntokenized_wprompt_test = test_dataset.map(preprocess_function_wprompt, batched=True)\n\ntokenized_wprompt_train = tokenized_wprompt_train.map(lambda e: {'labels': label_dict[e['labels']]})\ntokenized_wprompt_val = tokenized_wprompt_val.map(lambda e: {'labels': label_dict[e['labels']]})\ntokenized_wprompt_test = tokenized_wprompt_test.map(lambda e: {'labels': label_dict[e['labels']]})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T16:48:55.779280Z","iopub.execute_input":"2025-05-26T16:48:55.779501Z","iopub.status.idle":"2025-05-26T16:48:59.935335Z","shell.execute_reply.started":"2025-05-26T16:48:55.779483Z","shell.execute_reply":"2025-05-26T16:48:59.934253Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8544 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e5451ae385240adaa8cfe3e22b023d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1101 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8bb64d1971d4b639f023753d0d73214"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2210 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e17706cd2f4f41ea9702016d759c85dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8544 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6264083e1e3d40ca9ba8f78061e990ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1101 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d62a41c22f7f4b83a3b94b05b247569c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2210 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b65cfeebeba54d11b82afeccbf9039b9"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"\nUNFREEZE_EPOCH = 5\nMODEL = RobertaSentimentUnfreeze(model_name='cardiffnlp/twitter-roberta-base-sentiment', \n                                 num_labels=5, unfreeze_strat='after_n', unfreeze_epoch=UNFREEZE_EPOCH)\n#MODEL.load_state_dict(torch.load('/kaggle/input/sst5_tuned/pytorch/default/1/after_n_model_weights.pth', weights_only=True))\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nCLF_LR = 5e-5\nBACKBONE_LR = 5e-6  # very small so it won't overfit so fast\nWD = 0.01\nBATCH_SIZE = 26\nEPOCHS = 30\n\nTRAIN_LOSSI = []\nVAL_LOSSI = []\n\ntorch.cuda.empty_cache()\nMODEL.to(DEVICE);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T06:29:25.008857Z","iopub.execute_input":"2025-05-26T06:29:25.009136Z","iopub.status.idle":"2025-05-26T06:29:41.601851Z","shell.execute_reply.started":"2025-05-26T06:29:25.009115Z","shell.execute_reply":"2025-05-26T06:29:41.600633Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2177479aa3f04f5db71cc1f744d59bde"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"def collate_fn(batch):\n    return {\n        'input_ids': torch.stack([torch.tensor(x['input_ids']) for x in batch]),\n        'attention_mask': torch.stack([torch.tensor(x['attention_mask']) for x in batch]),\n        'labels': torch.tensor([x['labels'] for x in batch])\n    }\n\ntrain_loader = DataLoader(tokenized_wprompt_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(tokenized_wprompt_val, batch_size=BATCH_SIZE, collate_fn=collate_fn)\ntest_loader = DataLoader(tokenized_wprompt_test, batch_size=BATCH_SIZE, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T16:48:59.936279Z","iopub.execute_input":"2025-05-26T16:48:59.936618Z","iopub.status.idle":"2025-05-26T16:49:00.081393Z","shell.execute_reply.started":"2025-05-26T16:48:59.936586Z","shell.execute_reply":"2025-05-26T16:49:00.080077Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-c4fea81a94bc>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     }\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_wprompt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_wprompt_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_wprompt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'BATCH_SIZE' is not defined"],"ename":"NameError","evalue":"name 'BATCH_SIZE' is not defined","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"train_lossi = []\ntrain_f1s = []\nval_lossi = []\nval_f1s = []\n\ns = time.time()\ntrain_loop(MODEL, train_loader, val_loader, EPOCHS, CLF_LR, BACKBONE_LR, WD, train_lossi, val_lossi, train_f1s, val_f1s, 'aftern_wprompt_weights')\ne = time.time()\nprint(f'Training completed in {(e-s)/60:.4f} mins')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T06:29:41.611167Z","iopub.execute_input":"2025-05-26T06:29:41.611386Z","iopub.status.idle":"2025-05-26T09:16:41.116887Z","shell.execute_reply.started":"2025-05-26T06:29:41.611368Z","shell.execute_reply":"2025-05-26T09:16:41.115719Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0626f28599e24dffaeba11a1469c9879"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0830532702a429da5b389e0f2b542b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f539e41244f42639aa231b55362dcb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7f04a1a3f294b6989f87d5be25e84d2"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.3117 | Train F1: 0.3348 | Val Loss: 1.2409 | Val F1: 0.4247 | Val Acc: 0.4414\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b99852efd0f4b16b55f32cb1c9d2300"}},"metadata":{}},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.2760 | Train F1: 0.3729 | Val Loss: 1.2249 | Val F1: 0.3761 | Val Acc: 0.4441\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8042052732a942378c464727b26ddfbe"}},"metadata":{}},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.2551 | Train F1: 0.3789 | Val Loss: 1.2003 | Val F1: 0.4072 | Val Acc: 0.4623\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"565f7d558cf34173bffb7926208fe5ed"}},"metadata":{}},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.2559 | Train F1: 0.3833 | Val Loss: 1.2013 | Val F1: 0.4154 | Val Acc: 0.4532\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519b637091644825be31b17b1d501972"}},"metadata":{}},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.2413 | Train F1: 0.4017 | Val Loss: 1.1897 | Val F1: 0.4172 | Val Acc: 0.4650\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"717facc637c74b829b7c28686a44fb31"}},"metadata":{}},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.2411 | Train F1: 0.3884 | Val Loss: 1.2162 | Val F1: 0.4313 | Val Acc: 0.4514\nunfreezing all\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"999f9fc4059f4dfc93a5864ded187b50"}},"metadata":{}},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.1274 | Train F1: 0.4630 | Val Loss: 1.0643 | Val F1: 0.4770 | Val Acc: 0.5186\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58142f82876b4d7aa4830732dd06a4c9"}},"metadata":{}},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.0119 | Train F1: 0.5228 | Val Loss: 1.1125 | Val F1: 0.5105 | Val Acc: 0.5295\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b076264bf4724701917e73cb2cae50cd"}},"metadata":{}},{"name":"stdout","text":"Epoch 9 | Train Loss: 0.9535 | Train F1: 0.5532 | Val Loss: 1.0641 | Val F1: 0.5353 | Val Acc: 0.5477\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0608e09c4ca944599256d94d1344bf7b"}},"metadata":{}},{"name":"stdout","text":"Epoch 10 | Train Loss: 0.9016 | Train F1: 0.5864 | Val Loss: 1.0643 | Val F1: 0.5253 | Val Acc: 0.5531\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5921f407ec140a68df439d28abbd5e8"}},"metadata":{}},{"name":"stdout","text":"Epoch 11 | Train Loss: 0.8527 | Train F1: 0.6082 | Val Loss: 1.1062 | Val F1: 0.5514 | Val Acc: 0.5631\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bb4352a634b4ec39de206eda5ed3ad6"}},"metadata":{}},{"name":"stdout","text":"Epoch 12 | Train Loss: 0.8044 | Train F1: 0.6301 | Val Loss: 1.1474 | Val F1: 0.5378 | Val Acc: 0.5522\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee598cc3c1214b7b8a1542f9f03a62ec"}},"metadata":{}},{"name":"stdout","text":"Epoch 13 | Train Loss: 0.7723 | Train F1: 0.6491 | Val Loss: 1.1763 | Val F1: 0.5264 | Val Acc: 0.5377\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0722d19d58ee4d579cdcfbec3d3ebf65"}},"metadata":{}},{"name":"stdout","text":"Epoch 14 | Train Loss: 0.7431 | Train F1: 0.6652 | Val Loss: 1.1889 | Val F1: 0.5368 | Val Acc: 0.5486\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 15:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82ea9ee37bc94419af2bebb945c21e8d"}},"metadata":{}},{"name":"stdout","text":"Epoch 15 | Train Loss: 0.7094 | Train F1: 0.6765 | Val Loss: 1.2548 | Val F1: 0.5350 | Val Acc: 0.5513\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 16:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11bdb8e8a2284025be9f8dba09015b7c"}},"metadata":{}},{"name":"stdout","text":"Epoch 16 | Train Loss: 0.6757 | Train F1: 0.7070 | Val Loss: 1.2681 | Val F1: 0.5409 | Val Acc: 0.5477\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 17:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0977fdcbf9a4446ead144053b3c76e22"}},"metadata":{}},{"name":"stdout","text":"Epoch 17 | Train Loss: 0.6532 | Train F1: 0.7136 | Val Loss: 1.2793 | Val F1: 0.5398 | Val Acc: 0.5495\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 18:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"642189701e4a44ed82d58f30189420c4"}},"metadata":{}},{"name":"stdout","text":"Epoch 18 | Train Loss: 0.6279 | Train F1: 0.7255 | Val Loss: 1.3584 | Val F1: 0.5337 | Val Acc: 0.5359\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 19:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efee707efc414671b5649a98278203be"}},"metadata":{}},{"name":"stdout","text":"Epoch 19 | Train Loss: 0.6149 | Train F1: 0.7321 | Val Loss: 1.3557 | Val F1: 0.5402 | Val Acc: 0.5441\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 20:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"478fd11f0175445e9496e6b87ef6ce63"}},"metadata":{}},{"name":"stdout","text":"Epoch 20 | Train Loss: 0.5859 | Train F1: 0.7478 | Val Loss: 1.4007 | Val F1: 0.5318 | Val Acc: 0.5368\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 21:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca80b09c0478402e8b0ff3193a4e816b"}},"metadata":{}},{"name":"stdout","text":"Epoch 21 | Train Loss: 0.5732 | Train F1: 0.7533 | Val Loss: 1.4041 | Val F1: 0.5438 | Val Acc: 0.5468\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 22:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"221428e989384f6fa2e9d5c29f6d3229"}},"metadata":{}},{"name":"stdout","text":"Epoch 22 | Train Loss: 0.5553 | Train F1: 0.7653 | Val Loss: 1.4779 | Val F1: 0.5279 | Val Acc: 0.5322\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 23:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b9616982e14b9e826037db5b3064f3"}},"metadata":{}},{"name":"stdout","text":"Epoch 23 | Train Loss: 0.5463 | Train F1: 0.7725 | Val Loss: 1.4632 | Val F1: 0.5376 | Val Acc: 0.5441\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 24:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdb6e125aebe4662902fa098052400c8"}},"metadata":{}},{"name":"stdout","text":"Epoch 24 | Train Loss: 0.5224 | Train F1: 0.7806 | Val Loss: 1.4844 | Val F1: 0.5365 | Val Acc: 0.5395\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 25:   0%|          | 0/329 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bd7886caac34147aab7d38404459742"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-d83884b1b3a8>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLF_LR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBACKBONE_LR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lossi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_lossi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aftern_wprompt_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training completed in {(e-s)/60:.4f} mins'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-850e457b13e9>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, train_loader, val_loader, epochs, clf_lr, back_lr, wd, tlossi, vlossi, tf1s, vf1s, save_fname)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":22},{"cell_type":"markdown","source":"KeyboardInterrupt when overfitting","metadata":{}},{"cell_type":"code","source":"# test texts also have prompt\n\nMODEL.load_state_dict(torch.load('/kaggle/working/aftern_wprompt_weights.pth', map_location=DEVICE, weights_only=True))\nprint(evaluate_model(MODEL, test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T09:18:39.721924Z","iopub.execute_input":"2025-05-26T09:18:39.722253Z","iopub.status.idle":"2025-05-26T09:19:17.232212Z","shell.execute_reply.started":"2025-05-26T09:18:39.722228Z","shell.execute_reply":"2025-05-26T09:19:17.231442Z"}},"outputs":[{"name":"stdout","text":"{'f1': 0.5556695031280695, 'accuracy': 0.5746606334841629}\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# Trying triplet loss","metadata":{}},{"cell_type":"code","source":"train_dataset = train_dataset.map(lambda e: {'labels': label_dict[e['labels']]})\nval_dataset = val_dataset.map(lambda e: {'labels': label_dict[e['labels']]})\ntest_dataset = test_dataset.map(lambda e: {'labels': label_dict[e['labels']]})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T16:51:34.323070Z","iopub.execute_input":"2025-05-26T16:51:34.323378Z","iopub.status.idle":"2025-05-26T16:51:35.248622Z","shell.execute_reply.started":"2025-05-26T16:51:34.323356Z","shell.execute_reply":"2025-05-26T16:51:35.247688Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8544 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd2aa8aa21c2473da83f95defb1c91b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1101 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d850ef52f975449680717267fb5ad3a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2210 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"621486ee3feb4fcb81804f78792dbfc4"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"class RobertaSentimentUnfreezeTriplet(nn.Module):\n    def __init__(self, model_name, num_labels, unfreeze_strat, unfreeze_epoch, triplet_loss_weight):\n        super().__init__()\n        \n        full_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n        self.roberta = full_model.roberta\n        self.classifier = nn.Sequential(nn.Linear(768, 768, bias=True),\n                                        nn.Dropout(p=0.1, inplace=False),\n                                        nn.Linear(768, num_labels, bias=True))\n        self.triplet_loss_weight = triplet_loss_weight\n        self.triplet_loss_fn = nn.TripletMarginLoss(margin=1.0, p=2)\n        self.ce_loss_fn = nn.CrossEntropyLoss()\n        del full_model\n        \n        self.unfreeze_strat = unfreeze_strat\n        self.encoder_layers = len(self.roberta.encoder.layer)\n        self.is_unfreezed = False\n        self.unfreeze_epoch = unfreeze_epoch\n        self._freeze_all()\n\n        # cuda out of memory\n        self.roberta.gradient_checkpointing_enable()\n    \n    def _freeze_all(self):\n        for param in self.roberta.parameters():\n            param.requires_grad = False\n\n    def _unfreeze_all_after_n(self, epoch):\n        if epoch > self.unfreeze_epoch:\n            print('unfreezing all')\n            for param in self.roberta.parameters():\n                param.requires_grad = True\n            self.is_unfreezed = True        \n\n    def _unfreeze_layerwise(self, epoch):\n        if epoch <= self.unfreeze_epoch:\n            return\n\n        # unfreeze 1 layer each '// n' epoch\n        layers_to_unfreeze = min((epoch - self.unfreeze_epoch) // 8, self.encoder_layers)\n        for i in range(self.encoder_layers - layers_to_unfreeze, self.encoder_layers):\n            for param in self.roberta.encoder.layer[i].parameters():\n                param.requires_grad = True\n                \n        print(f'unfreezing {layers_to_unfreeze} top layers')\n\n        if layers_to_unfreeze >= self.encoder_layers:\n            self.is_unfreezed = True\n\n    def update_unfreeze_status(self, epoch):\n        if self.is_unfreezed:\n            return\n        elif self.unfreeze_strat == 'after_n':\n            self._unfreeze_all_after_n(epoch)\n        elif self.unfreeze_strat == 'layerwise':\n            self._unfreeze_layerwise(epoch)\n\n    def forward(self, input_ids, attention_mask, labels=None, anchor_ids=None, positive_ids=None, negative_ids=None):\n        out = self.roberta(input_ids=input_ids)\n        pool = out.last_hidden_state[:, 0, :]\n        logits = self.classifier(pool)\n\n        triplet_loss = None\n        if anchor_ids is not None and positive_ids is not None and negative_ids is not None:\n            anchor_emb = self.roberta(anchor_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n            positive_emb = self.roberta(positive_ids).last_hidden_state[:, 0, :]\n            negative_emb = self.roberta(negative_ids).last_hidden_state[:, 0, :]\n            triplet_loss = self.triplet_loss_fn(anchor_emb, positive_emb, negative_emb)\n        \n        if labels is not None:\n            ce_loss = self.ce_loss_fn(logits, labels)\n            total_loss = ce_loss + self.triplet_loss_weight * triplet_loss if triplet_loss is not None else ce_loss\n            return {\"loss\": total_loss, \"logits\": logits, \"triplet_loss\": triplet_loss}\n        return {\"logits\": logits}\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:09:46.718782Z","iopub.execute_input":"2025-05-26T17:09:46.719095Z","iopub.status.idle":"2025-05-26T17:09:46.730768Z","shell.execute_reply.started":"2025-05-26T17:09:46.719073Z","shell.execute_reply":"2025-05-26T17:09:46.730081Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def generate_triplets(dataset):\n    triplets = []\n    class_to_indices = {label: [] for label in set(dataset['labels'])}\n    \n    for idx, label in enumerate(dataset['labels']):\n            class_to_indices[label].append(idx)\n        \n    for idx, (text, label) in enumerate(zip(dataset['text_wprompt'], dataset['labels'])):\n        positive_idx = random.choice(class_to_indices[label])\n            \n        # close class for negative example\n        negative_label = abs(label + random.choice([-1, 1]))\n        if negative_label == 5:\n            negative_label = 3\n            \n        negative_idx = random.choice(class_to_indices[negative_label])\n            \n        triplets.append({\n            'anchor': text,\n            'positive': dataset['text_wprompt'][positive_idx],\n            'negative': dataset['text_wprompt'][negative_idx],\n            'label': label\n        })\n        \n    return Dataset.from_dict({\n        'anchor': [t['anchor'] for t in triplets],\n        'positive': [t['positive'] for t in triplets],\n        'negative': [t['negative'] for t in triplets],\n        'label': [t['label'] for t in triplets]\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:09:50.731689Z","iopub.execute_input":"2025-05-26T17:09:50.731984Z","iopub.status.idle":"2025-05-26T17:09:50.738220Z","shell.execute_reply.started":"2025-05-26T17:09:50.731960Z","shell.execute_reply":"2025-05-26T17:09:50.737318Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"train_triplets = generate_triplets(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T16:51:35.499982Z","iopub.execute_input":"2025-05-26T16:51:35.500297Z","iopub.status.idle":"2025-05-26T16:53:48.368580Z","shell.execute_reply.started":"2025-05-26T16:51:35.500269Z","shell.execute_reply":"2025-05-26T16:53:48.367863Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def triplet_collate_fn(batch):\n    anchor = tokenizer(\n        [x['anchor'] for x in batch],\n        truncation=True,\n        padding='max_length',\n        max_length=512,\n        return_tensors='pt'\n    )\n    \n    positive = tokenizer(\n        [x['positive'] for x in batch],\n        truncation=True,\n        padding='max_length',\n        max_length=512,\n        return_tensors='pt'\n    )\n    \n    negative = tokenizer(\n        [x['negative'] for x in batch],\n        truncation=True,\n        padding='max_length',\n        max_length=512,\n        return_tensors='pt'\n    )\n    \n    return {\n        'input_ids': anchor['input_ids'],\n        'attention_mask': anchor['attention_mask'],\n        'anchor_ids': anchor['input_ids'],\n        #'anchor_mask': anchor['attention_mask'],\n        'positive_ids': positive['input_ids'],\n        #'positive_mask': positive['attention_mask'],\n        'negative_ids': negative['input_ids'],\n        #'negative_mask': negative['attention_mask'],\n        'labels': torch.tensor([x['label'] for x in batch])\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:10:03.977225Z","iopub.execute_input":"2025-05-26T17:10:03.977629Z","iopub.status.idle":"2025-05-26T17:10:03.983011Z","shell.execute_reply.started":"2025-05-26T17:10:03.977596Z","shell.execute_reply":"2025-05-26T17:10:03.982099Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"MODEL.to('cpu')\ntorch.cuda.empty_cache()\ndel MODEL","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:11:47.074920Z","iopub.execute_input":"2025-05-26T17:11:47.075229Z","iopub.status.idle":"2025-05-26T17:11:48.068455Z","shell.execute_reply.started":"2025-05-26T17:11:47.075205Z","shell.execute_reply":"2025-05-26T17:11:48.067748Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"\nUNFREEZE_EPOCH = 7\nTP_LOSS_WEIGHT = 0.2\nMODEL = RobertaSentimentUnfreezeTriplet(model_name='cardiffnlp/twitter-roberta-base-sentiment', \n                                        num_labels=5, unfreeze_strat='after_n', unfreeze_epoch=UNFREEZE_EPOCH, triplet_loss_weight=TP_LOSS_WEIGHT)\n#MODEL.load_state_dict(torch.load('/kaggle/input/sst5_tuned/pytorch/default/1/after_n_model_weights.pth', weights_only=True))\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nCLF_LR = 5e-5\nBACKBONE_LR = 5e-6  # very small so it won't overfit so fast\nWD = 0.01\nBATCH_SIZE = 20\nEPOCHS = 35\n\nTRAIN_LOSSI = []\nVAL_LOSSI = []\n\ntorch.cuda.empty_cache()\nMODEL.to(DEVICE);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:11:52.871893Z","iopub.execute_input":"2025-05-26T17:11:52.872213Z","iopub.status.idle":"2025-05-26T17:11:53.372943Z","shell.execute_reply.started":"2025-05-26T17:11:52.872189Z","shell.execute_reply":"2025-05-26T17:11:53.371660Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"train_loader = DataLoader(train_triplets, batch_size=BATCH_SIZE, shuffle=True,collate_fn=triplet_collate_fn)\nval_loader = DataLoader(tokenized_wprompt_val, batch_size=BATCH_SIZE, collate_fn=collate_fn)\ntest_loader = DataLoader(tokenized_wprompt_test, batch_size=BATCH_SIZE, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:11:53.404853Z","iopub.execute_input":"2025-05-26T17:11:53.405136Z","iopub.status.idle":"2025-05-26T17:11:53.410385Z","shell.execute_reply.started":"2025-05-26T17:11:53.405111Z","shell.execute_reply":"2025-05-26T17:11:53.409583Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"def train_loop_triplets(model, train_loader, val_loader, epochs, clf_lr, back_lr, wd, tlossi, vlossi, tf1s, vf1s, save_fname):\n    \n    optimizer = AdamW([\n        {'params': model.classifier.parameters(), 'lr': clf_lr},\n        {'params': [p for p in model.roberta.parameters() if p.requires_grad], 'lr': back_lr}\n    ], weight_decay=wd)\n\n    load_f1 = load(\"f1\")\n    load_accuracy = load(\"accuracy\")\n    best_val_metrics_sum = -1\n\n    for epoch in tqdm(range(epochs)):\n\n        # basic lr scheduler\n        if epoch > 7:\n            clf_lr *= 0.9\n            back_lr *= 0.9\n        \n        model.update_unfreeze_status(epoch)\n\n        new_unfreezed_params = [p for p in model.roberta.parameters() if p.requires_grad]\n        \n        param_groups = [\n            {'params': model.classifier.parameters(), 'lr': clf_lr},\n            {'params': new_unfreezed_params, 'lr': back_lr}\n        ]\n        optimizer = AdamW(param_groups, weight_decay=wd)\n\n        all_preds_train = []\n        all_labels_train = []\n        model.train()\n        train_loss = 0\n        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n            inputs = batch['input_ids'].to(DEVICE)\n            masks = batch['attention_mask'].to(DEVICE)\n            labels = batch['labels'].to(DEVICE)\n            \n            optimizer.zero_grad()\n            \n            outputs = model(\n                input_ids=batch['input_ids'].to(DEVICE),\n                attention_mask=batch['attention_mask'].to(DEVICE),\n                labels=batch['labels'].to(DEVICE),\n                anchor_ids=batch['anchor_ids'].to(DEVICE),\n                positive_ids=batch['positive_ids'].to(DEVICE),\n                negative_ids=batch['negative_ids'].to(DEVICE),\n                #anchor_mask=batch['anchor_mask'].to(DEVICE),\n                #positive_mask=batch['positive_mask'].to(DEVICE),\n                #negative_mask=batch['negative_mask'].to(DEVICE)\n            )\n            \n            logits = outputs['logits']\n            loss = outputs['loss']\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n            train_loss += loss.item()\n\n            preds = logits.argmax(dim=-1).detach().cpu().numpy()\n            all_preds_train.extend(preds)\n            all_labels_train.extend(labels)\n\n        epoch_train_loss = train_loss/len(train_loader)\n        epoch_train_f1 = load_f1.compute(predictions=all_preds_train, references=all_labels_train, average='macro')[\"f1\"]\n        \n        tlossi.append(epoch_train_loss)\n        tf1s.append(epoch_train_f1)\n\n        all_preds_val = []\n        all_labels_val = []\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                inputs = batch['input_ids'].to(DEVICE)\n                masks = batch['attention_mask'].to(DEVICE)\n                labels = batch['labels'].to(DEVICE)\n                \n                outputs = model(input_ids=inputs, attention_mask=masks, labels=labels)\n                logits = outputs['logits']\n                loss = outputs['loss']\n                val_loss += loss.item()\n                \n                preds = logits.argmax(dim=-1).detach().cpu().numpy()\n                all_preds_val.extend(preds)\n                all_labels_val.extend(labels)\n                \n        epoch_val_loss = val_loss/len(val_loader)\n        epoch_val_f1 = load_f1.compute(predictions=all_preds_val, references=all_labels_val, average='macro')[\"f1\"]\n        epoch_val_acc = load_accuracy.compute(predictions=all_preds_val, references=all_labels_val)[\"accuracy\"]\n        vlossi.append(epoch_val_loss)\n        vf1s.append(epoch_val_f1)\n\n        val_metrics_sum = epoch_val_f1 + epoch_val_acc\n        # save best model\n        if val_metrics_sum > best_val_metrics_sum:\n            best_val_metrics_sum = val_metrics_sum\n            torch.save(model.state_dict(), f'{save_fname}.pth')\n            \n            \n        print(f'Epoch {epoch+1} | Train Loss: {epoch_train_loss:.4f} | Train F1: {epoch_train_f1:.4f} | Val Loss: {epoch_val_loss:.4f} | Val F1: {epoch_val_f1:.4f} | Val Acc: {epoch_val_acc:.4f}')\n        torch.cuda.empty_cache()\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:11:54.558980Z","iopub.execute_input":"2025-05-26T17:11:54.559433Z","iopub.status.idle":"2025-05-26T17:11:54.572606Z","shell.execute_reply.started":"2025-05-26T17:11:54.559367Z","shell.execute_reply":"2025-05-26T17:11:54.571802Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"train_lossi = []\ntrain_f1s = []\nval_lossi = []\nval_f1s = []\n\ns = time.time()\ntrain_loop_triplets(MODEL, train_loader, val_loader, EPOCHS, CLF_LR, BACKBONE_LR, WD, train_lossi, val_lossi, train_f1s, val_f1s, 'aftern_wprompt_tploss_weights')\ne = time.time()\nprint(f'Training completed in {(e-s)/60:.4f} mins')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T17:11:55.876587Z","iopub.execute_input":"2025-05-26T17:11:55.876875Z","execution_failed":"2025-05-27T04:47:22.459Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e5ae9dc4abc4276971c7ef1ac26f11e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fc7f6fa54a243399fd91e66b40e7424"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.7778 | Train F1: 0.3008 | Val Loss: 1.2580 | Val F1: 0.3669 | Val Acc: 0.4305\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b156191a88474ef48df982a125e91b30"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.7332 | Train F1: 0.3593 | Val Loss: 1.2298 | Val F1: 0.4333 | Val Acc: 0.4578\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00f645d922984712b51edfc73ade8db0"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.7243 | Train F1: 0.3749 | Val Loss: 1.2256 | Val F1: 0.4076 | Val Acc: 0.4550\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d48c0d43ad8471fa49b96b89c188c5b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.7067 | Train F1: 0.3761 | Val Loss: 1.2221 | Val F1: 0.4486 | Val Acc: 0.4532\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"980460144e9345588800ba09c6168d1b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.7045 | Train F1: 0.3726 | Val Loss: 1.2263 | Val F1: 0.4569 | Val Acc: 0.4596\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb57903c288a41cd937d145f26808b0b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.7021 | Train F1: 0.3892 | Val Loss: 1.2118 | Val F1: 0.4475 | Val Acc: 0.4614\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5458a560b3c34ab6b8cc8d77d1c5c3b8"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.6949 | Train F1: 0.3832 | Val Loss: 1.1924 | Val F1: 0.4407 | Val Acc: 0.4469\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed8dd1c77a8c43b48d996c181756cb8d"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.6913 | Train F1: 0.3914 | Val Loss: 1.2071 | Val F1: 0.4523 | Val Acc: 0.4559\nunfreezing all\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdc4f1eb921b4016b7c9dada69d3eee1"}},"metadata":{}},{"name":"stdout","text":"Epoch 9 | Train Loss: 1.3516 | Train F1: 0.4612 | Val Loss: 1.0697 | Val F1: 0.4172 | Val Acc: 0.5150\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c2dda4c4f0a4aa1a94af6a9001a4a30"}},"metadata":{}},{"name":"stdout","text":"Epoch 10 | Train Loss: 1.2108 | Train F1: 0.5132 | Val Loss: 1.0982 | Val F1: 0.5129 | Val Acc: 0.5132\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1039e1fcf31943f6bc499ea7c8ef74ce"}},"metadata":{}},{"name":"stdout","text":"Epoch 11 | Train Loss: 1.1192 | Train F1: 0.5519 | Val Loss: 1.0877 | Val F1: 0.5455 | Val Acc: 0.5604\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c07772ea6693429188db074f78949917"}},"metadata":{}},{"name":"stdout","text":"Epoch 12 | Train Loss: 1.0527 | Train F1: 0.5875 | Val Loss: 1.1796 | Val F1: 0.5242 | Val Acc: 0.5395\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"630a3df096d44b9d9d8c08ee00017e4c"}},"metadata":{}},{"name":"stdout","text":"Epoch 13 | Train Loss: 0.9937 | Train F1: 0.6115 | Val Loss: 1.1313 | Val F1: 0.5378 | Val Acc: 0.5513\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60e50b5bf1a14950908d783fa23c346e"}},"metadata":{}},{"name":"stdout","text":"Epoch 14 | Train Loss: 0.9348 | Train F1: 0.6488 | Val Loss: 1.2247 | Val F1: 0.5495 | Val Acc: 0.5486\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 15:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c5181d84ed84374b3197bd66b2ca046"}},"metadata":{}},{"name":"stdout","text":"Epoch 15 | Train Loss: 0.8796 | Train F1: 0.6658 | Val Loss: 1.1949 | Val F1: 0.5404 | Val Acc: 0.5568\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 16:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8905dc7d6f644022bed8f72182971056"}},"metadata":{}},{"name":"stdout","text":"Epoch 16 | Train Loss: 0.8288 | Train F1: 0.6913 | Val Loss: 1.2745 | Val F1: 0.5335 | Val Acc: 0.5304\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 17:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25f51d2865a1496493c464472c1b7b4c"}},"metadata":{}},{"name":"stdout","text":"Epoch 17 | Train Loss: 0.8008 | Train F1: 0.7042 | Val Loss: 1.3770 | Val F1: 0.5493 | Val Acc: 0.5568\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 18:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b47676cf48f14009b950ef4e6a35a32b"}},"metadata":{}},{"name":"stdout","text":"Epoch 18 | Train Loss: 0.7584 | Train F1: 0.7247 | Val Loss: 1.4148 | Val F1: 0.5433 | Val Acc: 0.5477\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 19:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d18b2c0f8edb4d3cbf8147d3d753def0"}},"metadata":{}},{"name":"stdout","text":"Epoch 19 | Train Loss: 0.7257 | Train F1: 0.7433 | Val Loss: 1.4755 | Val F1: 0.5393 | Val Acc: 0.5431\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 20:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"471791bfc95e447b92cf27572dd9c387"}},"metadata":{}},{"name":"stdout","text":"Epoch 20 | Train Loss: 0.6845 | Train F1: 0.7510 | Val Loss: 1.4438 | Val F1: 0.5456 | Val Acc: 0.5495\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 21:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c82898d8aea54f74af8ac1081cfadbbc"}},"metadata":{}},{"name":"stdout","text":"Epoch 21 | Train Loss: 0.6605 | Train F1: 0.7628 | Val Loss: 1.5174 | Val F1: 0.5420 | Val Acc: 0.5450\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 22:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8de3c6757f584f67aa99f590602de690"}},"metadata":{}},{"name":"stdout","text":"Epoch 22 | Train Loss: 0.6332 | Train F1: 0.7700 | Val Loss: 1.5904 | Val F1: 0.5327 | Val Acc: 0.5341\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 23:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e46ad6104cc24611ad2c7bf49e9f4bc9"}},"metadata":{}},{"name":"stdout","text":"Epoch 23 | Train Loss: 0.6216 | Train F1: 0.7812 | Val Loss: 1.6359 | Val F1: 0.5253 | Val Acc: 0.5268\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 24:   0%|          | 0/428 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faad63897c90418c91a62378217d918c"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# блин, забрали у меня гпу компьют, удалили мой чекпоинт и не дали посчитать метрики на тесте, а вернут гпу только через несколько дней..\n# но судя по метрикам на обучении, качество должно быть сравнимым с версией модели без триплет лосса, может чуть лучше\n# моё скромное предположение что аккураси на тесте была бы ~0.5727\n\n# в колабе уместил в гпу attention_mask для всех инпутов в триплет лоссе, но там комьют забрали ещё быстрее)\n# с масками возможно удалось бы добиться качества повыше, эх","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Paraphraze augmentations?","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}